<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Beacon3D: A Benchmark for 3D Vision-Language Understanding">
  <meta name="keywords" content="3D Vision-Language, 3D Scene Understanding, Benchmark, Multi-modal Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Beacon3D</title>

  <script>
    // functions borrowed from PaLM-E
    timeoutIds = [];
        
    function populateDemo(img) {
      console.log("img", img)

      var img1 = document.getElementById("scene1");
      img1.onclick = null;

      var img2 = document.getElementById("scene2");
      img2.onclick = null;

      var img3 = document.getElementById("scene3");
      img3.onclick = null;

      var img4 = document.getElementById("scene4");
      img4.onclick = null;

      var img5 = document.getElementById("scene5");
      img5.onclick = null;

      var img6 = document.getElementById("scene6");
      img6.onclick = null;

      for (const idx of [1,2,3,4,5]) {
        var instruction = document.getElementById("instruction"+idx);
        var response = document.getElementById("response"+idx);
        instruction.innerHTML = "";
        response.innerHTML = "";
      }

      model1 = scene1.getObjectByName("mesh")
      scene1.remove(model1)
      document.querySelector('#pose_loading').innerHTML = `<img src="assets/loading.svg" width="48" height="48">`

      var capability = document.querySelector('input[name="capability"]:checked').value;
      let assetUrl = new URL('./assets/scene_mesh/' + capability + img.id[5] + '.glb', document.URL)
      assetLoader1.load(assetUrl.href, gltf => {
        model1 = gltf.scene
        model1.name = "mesh"
        scene1.add(model1)
        document.querySelector('#pose_loading').innerHTML = ''

        img1.onclick = function() {populateDemo(img1)};
        img2.onclick = function() {populateDemo(img2)};
        img3.onclick = function() {populateDemo(img3)};
        img4.onclick = function() {populateDemo(img4)};
        img5.onclick = function() {populateDemo(img5)};
        img6.onclick = function() {populateDemo(img6)};

        var qas = img.alt.split("[SEP]");
        for (timeoutId of timeoutIds) {
            clearTimeout(timeoutId);
        }
        var delay = 0;
        for ([idx, qa] of qas.entries()) {
          idx += 1;
          qa = qa.split("[sep]")
          timeoutIds.push(setTimeout(displayDialogue, delay, qa, idx));
          delay += qa[1].length * 25;
        }
      }, undefined, (error) => {console.error(error)})
    }

    function typeWriter(txt, i, q, idx) {
      var instruction = document.getElementById("instruction"+idx);
      if (instruction.innerHTML == q) {
        if (i < txt.length) {
          document.getElementById("response"+idx).innerHTML += txt.charAt(i);
          i++;
          timeoutIds.push(setTimeout(typeWriter, 20, txt, i, q, idx));
        }
      }
    }

    function displayDialogue(qa, idx) {
      var instruction = document.getElementById("instruction"+idx);
      var response = document.getElementById("response"+idx);
      instruction.innerHTML = qa[0];
      response.innerHTML = "";
      typeWriter(qa[1], 0, qa[0], idx);
    }

  </script>

  <script type="importmap">
    {
      "imports": {
        "vue": "https://unpkg.com/vue@3/dist/vue.esm-browser.js",
        "three": "https://unpkg.com/three@0.127.0/build/three.module.js",
        "three/addons/": "https://unpkg.com/three@0.127.0/examples/jsm/"
      }
    }
  </script>

  <!-- imported in PaLM-E -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="https://github.com/palm-e/palm-e.github.io/blob/main/css/app.css">

  <link rel="stylesheet" href="https://github.com/palm-e/palm-e.github.io/blob/main/css/bootstrap.min.css">

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
  
  <script src="https://github.com/palm-e/palm-e.github.io/blob/main/js/app.js"></script>

  <!-- imported in Nerfies -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./assets/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="https://kit.fontawesome.com/69dc91e44b.js" crossorigin="anonymous"></script>

  <style>
    .description {
      font-size: 1.125rem;
      color: #374151; /* Tailwind's gray-700 */
      margin-bottom: 2rem;
    }
    .grid {
      display: grid;
      gap: 1.5rem;
      grid-template-columns: 1fr;
    }
    @media (min-width: 768px) {
      .grid {
        grid-template-columns: repeat(2, 1fr);
      }
    }
  </style>

</head>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" target="_blank" href="https://siyuanhuang.com/">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
        More Research
        </a>
        <div class="navbar-dropdown">
        <a class="navbar-item" target="_blank" href="https://embodied-generalist.github.io/">
          LEO
        </a>
        <a class="navbar-item" target="_blank" href="https://msr3d.github.io/">
          MSR3D
        </a>
        <a class="navbar-item" target="_blank" href="https://scene-verse.github.io/">
          SceneVerse
        </a>
        <a class="navbar-item" target="_blank" href="https://pq3d.github.io/">
          PQ3D
        </a>
        <a class="navbar-item" target="_blank" href="https://arnold-benchmark.github.io/">
          ARNOLD
        </a>
        </div>
      </div>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <img src="assets/logo.png" width="10%">
          <h1 class="title is-3 publication-title">Unveiling the Mist over 3D Vision-Language Understanding: Object-centric Evaluation with Chain-of-Analysis</h1>
          <h4 class="title is-4 publication-title">CVPR 2025</h4>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" href="https://huangjy-pku.github.io/">Jiangyong Huang</a><sup>1,2,‚ú∂</sup></span>
            <span class="author-block" style="margin-left: 1em;">
                <a target="_blank" href="https://buzz-beater.github.io/">Baoxiong Jia</a><sup>1,‚ú∂</sup></span>
            <span class="author-block" style="margin-left: 1em;">
                <a target="_blank" href="https://github.com/jetpackfirstme">Yan Wang</a><sup>1</sup></span>
            <span class="author-block" style="margin-left: 1em;">
              <a target="_blank" href="https://zhuziyu-edward.github.io/">Ziyu Zhu</a><sup>1,3</sup></span>
            <span class="author-block" style="margin-left: 1em;">
              <a target="_blank" href="https://github.com/Germany321">Xiongkun Linghu</a><sup>1</sup></span>
            <br/>
            <span class="author-block">
              <a target="_blank" href="https://liqing-ustc.github.io/">Qing Li</a><sup>1</sup></span>
            <span class="author-block" style="margin-left: 1em;">
              <a target="_blank" href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a><sup>1,2,3</sup></span>
            <span class="author-block" style="margin-left: 1em;">
              <a target="_blank" href="https://siyuanhuang.com/">Siyuan Huang</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Beijing Institute for General Artificial Intelligence (BIGAI)</span>
            <br/>
            <span class="author-block"><sup>2</sup>Peking University</span>
            <span class="author-block" style="margin-left: 1em;"><sup>3</sup>Tsinghua University</span>
          </div>

          <p style="font-size: 0.9em; padding: 0.5em 0 0 0;">‚ú∂ indicates equal contribution</p>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Arxiv Link. -->
              <span class="link-block">
                <a target="_blank" href="https://arxiv.org/abs/2503.22420"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a target="_blank" href="https://youtu.be/8hiGFwCQMjk"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Demo Link. -->
              <span class="link-block">
                <a target="_blank"
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="fa-regular fa-comments"></i>
                  </span>
                  <span>Demo</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a target="_blank"
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Data Link. -->
              <span class="link-block">
                <a target="_blank"
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="fa fa-database"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              <br/>Coming soon. Stay tuned.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">

    <!-- Paper video -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/8hiGFwCQMjk?si=_ryfpNopOCdhMyAX"
          title="YouTube video player" frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video -->

    <!-- Overview -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-4">Overview</h2>
        <img src="assets/teaser.png" alt="Illustrative overview of Beacon3D">
        <div class="content has-text-justified" style="margin-top: 5px;">
          <p>
            An illustration of Beacon3D, a novel benchmark for 3D grounding and question answering (QA) tasks.
            Beacon3D features an object-centric evaluation framework, with Grounding Chains (G-Chains) and Grounding-QA Chains (GQA-Chains) for each object.
            The evaluation adopts object-centric metrics to ensure robustness and utilizes chain-of-analysis for studies in task coherence.
            We also design various knowledge types such as class, appearance ("App."), geometry ("Geo."), spatial ("Spa."), and existence ("Exi.").
          </p>
        </div>

        <div class="content has-text-justified" style="width: 100%; margin: 0 auto;">
          <img src="assets/scenes.png" width="40%" alt="30 high-quality real 3D scenes in Beacon3D">
          <img src="assets/data_stats.png" width="59%" alt="Beacon3D data statistics">
          <p style="margin-top: -5px;">
            Beacon3D is built on 30 high-quality real 3D scenes meticulously selected from ScanNet, 3RScan, and MultiScan.
            The object-centric evaluation includes more than 800 objects and shows a diverse distribution of knowledge types in grounding and QA tasks.
          </p>
        </div>
      </div>
    </div>
    <!--/ Overview -->
    
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4 has-text-centered">Summary</h2>
        <div class="grid grid-cols-1 md:grid-cols-2 gap-6">

          <div class="bg-gray-100 py-6 rounded-xl text-left shadow" style="padding-left: 3rem; padding-right: 2.5rem;">
            <h2 class="flex items-center text-xl font-semibold mb-4">
              ü§î<span class="ml-2" style="font-size: large; font-weight: bold;">Limitations of existing 3D-VL benchmarks</span>
            </h2>
            <ul class="list-none space-y-2">
              <li style="color: rgb(177, 92, 92); font-weight: bold;">üóÉÔ∏è&nbsp; Flawed test data</li>
              <li style="color: rgb(177, 92, 92); font-weight: bold;">üìä&nbsp; Insufficient evaluation metrics</li>
              <li style="color: rgb(177, 92, 92); font-weight: bold;">üîó&nbsp; Isolation of grounding and QA tasks</li>
            </ul>
          </div>

          <div class="bg-gray-100 p-6 rounded-xl text-left shadow">
            <h2 class="flex items-center text-xl font-semibold mb-4">
              üí°<span class="ml-2" style="font-size: large; font-weight: bold;">Highlights of the Beacon3D benchmark</span>
            </h2>
            <ul class="list-none space-y-2">
              <li style="color: rgb(84, 156, 79); font-weight: bold;">üóÉÔ∏è&nbsp; High-quality test data</li>
              <li style="color: rgb(84, 156, 79); font-weight: bold;">üìä&nbsp; Object-centric evaluation metrics</li>
              <li style="color: rgb(84, 156, 79); font-weight: bold;">üîó&nbsp; Grounding Chain and Grounding-QA Chain</li>
            </ul>
          </div>
        </div>
        <br/>

      </div>
    </div>

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4 has-text-centered">From Existing 3D-VL Benchmarks to Beacon3D</h2>

        <!-- Test data -->
        <div class="content has-text-justified">
          <p>
            <b style="color: rgb(177, 92, 92);">üóÉÔ∏è Flawed test data.</b>
            We observe notable data flaws including ambiguous referential texts in the grounding task,
            ambiguous questions and incomplete answers in the QA task. Such flawed test data could undermine the reliability of evaluation results.
          </p>
        </div>
        <div style="width: 100%; margin: -20px auto 15px auto;">
          <figure style="text-align: center;">
          <img src="assets/data_flaw.png" alt="Flawed test data in existing 3D-VL benchmarks">
            <figcaption style="font-size: 14px; color: #666;">
              <i><b>Flawed test data in existing 3D-VL benchmarks:</b> the top row shows grounding data and the bottom row shows QA data.</i>
            </figcaption>
          </figure>
        </div>

        <div class="content has-text-justified">
          <p>
            <b style="color: rgb(84, 156, 79);">üóÉÔ∏è Beacon3D: high-quality test data.</b>
            We establish detailed annotation guidelines, ensuring precise and natural language to address prior data flaws.
            The human study across different 3D-VL benchmarks highlights the quality of Beacon3D test data.
          </p>
      </div>
        <div style="display: flex; justify-content: center; gap: 20px; margin: -15px auto 15px auto; width: 100%;">
          <figure style="text-align: center;">
            <img src="assets/data_quality_grouding.png" width="41%" style="margin-left: 1%; margin-right: 2%;" alt="Human study on the quality of grounding data">
            <img src="assets/data_quality_qa.png" width="41%" style="margin-left: 2%; margin-right: 1%;" alt="Human study on the quality of QA data">
            <figcaption style="font-size: 14px; color: #666;">
              <i><b>Human study on the quality of test data:</b> the left shows grounding data and the right shows QA data.</i>
            </figcaption>
          </figure>
    </div>
        <!--/ Test data -->

        <!-- Evaluation metrics -->
        <div class="content has-text-justified">
          <p>
            <b style="color: rgb(177, 92, 92);">üìä Insufficient evaluation metrics.</b>
            We find that simple metrics, such as averaging accuracy over individual QA pairs,
            are vulnerable to pitfalls like visual ignorance and weak language robustness,
            falling short in capturing true model capability.
          </p>
        </div>
        <div style="display: flex; justify-content: center; margin: -15px auto 15px auto; width: 100%;">
          <figure style="text-align: center;">
            <img src="assets/visual_ignorance.png" width="100%" style="margin-left: 2%; margin-right: 0%; margin-bottom: 5px;" alt="Model pitfall: visual ignorance">
            <figcaption style="font-size: 14px; color: #666;"><i><b>Model pitfall: visual ignorance</b></i></figcaption>
          </figure>
          <figure style="text-align: center;">
            <img src="assets/language_robustness.png" width="91.5%" style="margin-left: 1%; margin-right: -3%; margin-bottom: 4px;" alt="Model pitfall: weak language robustness">
            <figcaption style="font-size: 14px; color: #666;"><i><b>Model pitfall: weak language robustness</b></i></figcaption>
          </figure>
        </div>

        <div style="display: flex; gap: 20px; align-items: flex-start;">
          <!-- Left: Text -->
          <div style="flex: 1;">
            <div>
              We present two pilot studies to show the vulnerability of existing evaluation metrics to two model pitfalls:
              <ul style="list-style-type: disc; padding-left: 20px;">
                <li>
                  Visual ignorance: finetuning blind LLMs on SQA3D yields unexpectedly high accuracy,
                  indicating the deficiency in evaluating the visual capability of 3D-VL models.
                </li>
                <li>
                  Language robustness: rephrasing language yields moderate and significant performance shift in grounding and QA tasks respectively,
                  indicating that current 3D-VL models are susceptible to language variations.</li>
              </ul>
            </div>
          </div>
        
          <!-- Right: Images -->
          <div style="flex: 1;">
            <!-- Top image -->
            <figure style="text-align: center; margin-top: 25px; margin-bottom: 25px;">
              <img src="assets/sqa_blind.png" alt="Performance of blind LLMs on SQA3D" style="width: 100%;">
              <figcaption style="font-size: 14px; color: #666;"><i><b>Performance of blind LLMs on SQA3D ( <sup>‚Ä†</sup> denotes 3D-VL model)</b></i></figcaption>
            </figure>
        
            <!-- Bottom two images side-by-side -->
            <figure style="text-align: center; margin-bottom: 10px;">
              <div style="display: flex; gap: 10px; margin-bottom: -2px;">
                <img src="assets/rephrase_grounding.png" alt="Effect of rephrasing on grounding task" style="width: 49%;">
                <img src="assets/rephrase_qa.png" alt="Effect of rephrasing on QA task" style="width: 50%;">
              </div>
              <figcaption style="font-size: 14px; color: #666;"><i><b>Effect of rephrasing language on grounding (left) and QA (right) tasks</b></i></figcaption>
            </figure>
          </div>
        </div>

        <div class="content has-text-justified" style="margin-top: 5px;">
          <p>
            <b style="color: rgb(84, 156, 79);">üìä Beacon3D: object-centric evaluation metrics.</b>
            In contrast to previous per-case average metrics, we design three diverse test cases per object and adopt object-centric metrics,
            which require the model to make corrcet prediction in all three cases.
          </p>
        </div>
        <div style="display: flex; justify-content: center; margin: -15px auto 15px auto; width: 100%;">
          <figure style="text-align: center;">
            <img src="assets/grounding_example.png" width="100%" style="margin-left: 0%; margin-right: 0%; margin-bottom: 5px;" alt="Data example: three grounding texts per object">
            <figcaption style="font-size: 14px; color: #666;"><i><b>Data example: three grounding texts per object</b></i></figcaption>
          </figure>
          <figure style="text-align: center;">
            <img src="assets/obj_metrics.png" width="84%" style="margin-left: 1%; margin-right: -3%; margin-bottom: 3.5px;" alt="Object-centric metrics">
            <figcaption style="font-size: 14px; color: #666;"><i><b>Case-centric metrics vs. Object-centric metrics</b></i></figcaption>
          </figure>
        </div>
        <!--/ Evaluation metrics -->

        <!-- Grounding-QA coherence -->
        <div class="content has-text-justified" style="margin-top: 5px;">
          <p>
            <b style="color: rgb(84, 156, 79);">üîó Beacon3D: Grounding Chain.</b>
            We organize the grounding data into Grounding Chains following a coarse-to-fine scheme,
            which helps assess performance coherence across different granularities and identify the boundary of grounding capability.
          </p>
        </div>
        <div style="width: 80%; margin: -5px auto 15px;">
          <video poster="" id="grounding_chain" autoplay muted loop height="100%">
            <source src="assets/g_chain.mp4" type="video/mp4">
          </video>
        </div>

        <div class="content has-text-justified" style="margin-top: 5px;">
          <div>
            <b style="color: rgb(84, 156, 79);">üîó Beacon3D: Grounding-QA Chain.</b>
            Beacon3D links QA data to grounding data via shared referential texts of the target object.
            Each question queries a specific aspect (<i>e.g.</i>, appearance) of the object,
            forming a Grounding-QA Chain that enables analysis of grounding-QA coherence.
            We identify two types of broken coherence:
            <ul style="list-style-type: disc; margin-top: 5px; margin-left: 3%;">
              <li>
                Type 1: model fails to answer the queried content but can recognize that in grounding task, showing a lack of QA skills.
              </li>
              <li>
                Type 2: model correctly answers the question but fails to ground the target object, indicating shortcut behavior in QA.
            </ul>
          </div>
        </div>
        <div style="width: 90%; margin: -25px auto 0px;">
          <video poster="" id="grounding_chain" autoplay muted loop height="100%">
            <source src="assets/gqa_chain.mp4" type="video/mp4">
          </video>
        </div>
        <!--/ Grounding-QA coherence -->

      </div>
    </div>


    <!-- Demo -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width" id="demo">
        <h2 class="title is-3">Demo</h2>

        <div style="text-align: center;"><b>Select 3D VL capabilities</b></div>
        <br/>
        <div class="columns is-centered" style="position: relative;">
          <div class="control" style="display: flex; flex-direction: row; align-items: center; justify-content: center;">
            <label class="radio">
              <input value="captioning" type="radio" name="capability"> <b>Captioning</b>
            </label>

            <span style="width:6em"></span>

            <label class="radio">
              <input value="reasoning" type="radio" name="capability"> <b>Reasoning</b>
            </label>

            <span style="width:6em"></span>

            <label class="radio">
              <input value="dialogue" type="radio" name="capability"> <b>Dialogue</b>
            </label>

            <span style="width:6em"></span>

            <label class="radio">
              <input value="planning" type="radio" name="capability"> <b>Planning</b>
            </label>
          </div>
        </div>

        <div class="row">
          <div class="col-md-2 col-sm-2 col-xs-4">
            <img id="scene1" src="assets/scene_view/captioning1.jpg" width="100%"
              alt="State what you notice at the pointed location in the 3D representation.
              [sep] A donut with pink icing and sprinkles."
              onclick="populateDemo(this);">
          </div>
          
          <div class="col-md-2 col-sm-2 col-xs-4">
            <img id="scene2" src="assets/scene_view/captioning2.jpg" width="100%"
              alt="Explain the object at the pinpointed location in the 3D setting.
              [sep] A wooden chest of drawers."
              onclick="populateDemo(this);">
          </div>

          <div class="col-md-2 col-sm-2 col-xs-4">
            <img id="scene3" src="assets/scene_view/captioning3.jpg" width="100%"
              alt="Develop a description of the object at the specified position in the 3D backdrop.
              [sep] This is a black keyboard. It is in front of two monitors."
              onclick="populateDemo(this);">
          </div>

          <div class="col-md-2 col-sm-2 col-xs-4">
            <img id="scene4" src="assets/scene_view/captioning4.jpg" width="100%"
              alt="How does the object appear at the marked location in the 3D view?
              [sep] This is a white pillow. It is on the right side of the bed."
              onclick="populateDemo(this);">
          </div>

          <div class="col-md-2 col-sm-2 col-xs-4">
            <img id="scene5" src="assets/scene_view/captioning5.jpg" width="100%"
              alt="Relay a brief summary of this scene's elements.
              [sep] In this scene, there is a tall wardrobe standing on the wooden floor.
              The wardrobe is to the right of a bed and in front of a nightstand.
              It is also behind a chair and to the left of another chair.
              There are pillows lying on the bed, with different sizes and colors.
              Some pillows are close to each other, while others are far away from each other.
              A blanket is lying on the bed, close to one of the pillows.
              The room has white walls attached to the floor, giving it an architectural feel.
              The ceiling is overhead and attached to the walls.
              There is a curtain hanging on one of the walls, adding a touch of elegance to the room.
              Overall, this room provides a cozy and comfortable space for relaxation and sleep."
              onclick="populateDemo(this);">
          </div>

          <div class="col-md-2 col-sm-2 col-xs-4">
            <img id="scene6" src="assets/scene_view/captioning6.jpg" width="100%"
              alt="Can you walk me through the details of this scene?
              [sep] In this scene, there is a white rectangular metal heater connected to the wall.
              It is in front of a curtain and to the right of another curtain.
              There is also a closed glass window attached to the wall.
              The floor is made of wooden material and has a striped texture.
              There are several chairs in the room, with different sizes and colors.
              Some chairs are close to tables, while others are far away from them.
              The walls are flat and white, giving the room an architectural feel.
              The room appears to be a living room or dining area, with comfortable seating options and a cozy atmosphere."
              onclick="populateDemo(this);">
          </div>
        </div>

        <div class="row border rounded" style="padding-top:10px; padding-bottom:10px;">
          <div class="col-md-7">
            <div id="pose_loading" style="position: absolute; left: 26.55%; top: 51.1%;"></div>
            <canvas id="webgl_pose"></canvas>
          </div>

          <div class="col-md-5" style="transform: translate(-4.5px,0)">
            <div id="instruction1">Prompt text in gray.</div>
            <div><p id="response1" style="white-space: pre-line">LEO's response in blue shade.</p></div>
            <div id="instruction2"></div>
            <div><p id="response2" style="white-space: pre-line"></p></div>
            <div id="instruction3"></div>
            <div><p id="response3" style="white-space: pre-line"></p></div>
            <div id="instruction4"></div>
            <div><p id="response4" style="white-space: pre-line"></p></div>
            <div id="instruction5"></div>
            <div><p id="response5" style="white-space: pre-line"></p></div>
          </div>
        </div>

        <br>
        <br>

      </div>
    </div> -->
    <!--/ Demo -->


    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4 has-text-centered">Results and Findings</h2>
        <!-- Metrics -->
        <div class="content has-text-justified">
          <p>
            <b>Metrics.</b>
            Object-centric metrics elicit a significant performance drop compared to per-case metrics,
            suggesting that current 3D-VL models lack a comprehensive understanding of objects and are susceptible to language variations.
          </p>
        </div>
        <div style="display: flex; justify-content: center; gap: 0; margin: -10px auto 20px auto; width: 100%;">
          <figure style="text-align: center;">
            <img src="assets/results_grounding.png" width="39.7%" style="margin-right: 2%;" alt="Model performance in grounding task">
            <img src="assets/results_qa.png" width="44%" style="margin-left: 2%;" alt="Model performance in QA task">
            <figcaption style="font-size: 14px; color: #666; margin-top: 4px;">
              <i><b>Model performance in grounding (left) and QA (right) tasks:</b> "Case" denotes per-case metrics and "Obj." denotes object-centric metrics.</i>
            </figcaption>
          </figure>
        </div>
        <!--/ Metrics -->

        <!-- Chain analysis -->
        <div class="content has-text-justified">
          <p>
            <b>Chain analysis: GQA-Chain.</b>
            We visualize four types of GQA-Chains and observe a limited proportion of good grounding-QA coherence.
            <i>R</i><sub>1</sub> and <i>R</i><sub>2</sub> measure the two types of broken coherence, both hovering around 50%.
            This reveals a substantial gap between the skills of grounding and QA, and frequent shortcut behavior in QA.
          </p>
        </div>
        <div style="width: 100%; margin: -5px auto 15px auto;">
          <figure style="text-align: center;">
            <img src="assets/chain_analysis_gqa.png" style="margin-left: -2%;" alt="Chain analysis across GQA-Chains">
            <figcaption style="font-size: 14px; color: #666; margin-top: -10px;">
              <i><b>GQA-Chain analysis:</b> distribution of four types of GQA-Chains (left) and two metrics for evaluating broken grounding-QA coherence (right).</i>
            </figcaption>
          </figure>
        </div>

        <div style="display: flex; gap: 20px; align-items: flex-start; margin-bottom: 10px;">
          <!-- Left: Text -->
          <div style="flex: 0.55; margin-top: 30px;">
            <b>Chain analysis: G-Chain.</b>
            Evaluation across coarse-to-fine G-Chains shows that fine-grained grounding is more challenging than coarse.
            The difficulty is pronounced when the model fails on coarse texts.
            As fine-grained grounding is crucial to solid QA performance,
            our chain analysis highlights the need to improve 3D-VL models in fine-grained grounding for better grounding-QA coherence.
          </div>
        
          <!-- Right: Images -->
          <div style="flex: 0.45;">
            <!-- Top image -->
            <figure style="text-align: center;">
              <img src="assets/chain_analysis_g.png" alt="Chain analysis across G-Chains">
              <figcaption style="font-size: 14px; color: #666;">
                <i><b>G-Chain analysis:</b> distribution of four types of G-Chains.</i>
              </figcaption>
            </figure>
          </div>
        </div>
        <!--/ Chain analysis -->

        <!-- Additional insights -->
        <div class="content has-text-justified">
          <p>
            <b>Model insights.</b>
            Our evaluation indicates that incorporating LLMs to 3D-VL models weakens grounding capability and does not fundamentally enhance QA capability.
            This suggests the main bottleneck lies in 3D perception and VL alignment, rather than language modeling or reasoning ‚Äî LLMs' strength.
            Therefore, advancing 3D-VL models may rely more on stronger foundation models for 3D scene understanding than on leveraging LLMs.
          </p>
        </div>
        <!--/ Additional insights -->
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-4 has-text-centered">BibTex</h2>
    <p style="margin-bottom: 10px;">If you find our work helpful, please consider citing us:</p>
    <pre><code class="language-bibtex">@inproceedings{huang2025unveiling,
  title={Unveiling the Mist over 3D Vision-Language Understanding: Object-centric Evaluation with Chain-of-Analysis},
  author={Huang, Jiangyong and Jia, Baoxiong and Wang, Yan and Zhu, Ziyu and Linghu, Xiongkun and Li, Qing and Zhu, Song-Chun and Huang, Siyuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
        <p>
            This website is licensed under a <a rel="license"
            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
        </p>
        <p>
            Template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
        </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>


<!-- visualization code borrowed from SceneDiffuser -->
<script type="module">

  import * as THREE from 'three'
  import { OrbitControls } from 'three/addons/controls/OrbitControls.js'
  import {GLTFLoader} from 'three/addons/loaders/GLTFLoader.js'

  let canvas1 = document.querySelector('#webgl_pose')
  let scene1 = new THREE.Scene()
  let assetLoader1 = new GLTFLoader()
  let model1

  let camera1 = new THREE.PerspectiveCamera(45, 1.618 / 1.0, 0.1, 100)
  camera1.position.set(5.2, 3.9, -3.9)
  let grid1 = new THREE.GridHelper(30, 30)
  scene1.add(camera1)
  scene1.add(grid1)
  for (let i = 0; i <= 1; i++) {
    for (let k = 0; k <= 1; k++) {
      let spotLight = new THREE.SpotLight(0xAAAAAA)
      spotLight.position.set(50 * (i * 2 - 1), 100, 100 * (k * 2 - 1))
      scene1.add(spotLight)
    }
  }

  let controls1 = new OrbitControls(camera1, canvas1)
  controls1.enableZoom = true
  // controls2.enableDamping = true
  controls1.object.position.set(camera1.position.x, camera1.position.y, camera1.position.z)
  controls1.target = new THREE.Vector3(0, 0, 0)
  controls1.update()

  let renderer1 = new THREE.WebGLRenderer({
      canvas: canvas1,
      alpha: true,
  })
  renderer1.setPixelRatio(Math.min(window.devicePixelRatio, 2))
  renderer1.outputEncoding = THREE.sRGBEncoding
  renderer1.setAnimationLoop(() => {
    renderer1.render(scene1, camera1)
  });

  const radioButtons = document.querySelectorAll('input[name="capability"]')
  for (const radioButton of radioButtons) {
    radioButton.addEventListener('change', (e) => {
      var capability = radioButton.value;
      console.log("capability", capability)
      for (const rb of radioButtons) {rb.disabled = true}

      var img1 = document.getElementById("scene1");
      var img2 = document.getElementById("scene2");
      var img3 = document.getElementById("scene3");
      var img4 = document.getElementById("scene4");
      var img5 = document.getElementById("scene5");
      var img6 = document.getElementById("scene6");

      if (capability == "captioning") {
        img1.src = "assets/scene_view/captioning1.jpg"
        img1.alt = "State what you notice at the pointed location in the 3D representation. " +
                   "[sep] A donut with pink icing and sprinkles."

        img2.src = "assets/scene_view/captioning2.jpg"
        img2.alt = "Explain the object at the pinpointed location in the 3D setting. " +
                   "[sep] A wooden chest of drawers."

        img3.src = "assets/scene_view/captioning3.jpg"
        img3.alt = "Develop a description of the object at the specified position in the 3D backdrop. " +
                   "[sep] This is a black keyboard. It is in front of two monitors."

        img4.src = "assets/scene_view/captioning4.jpg"
        img4.alt = "How does the object appear at the marked location in the 3D view? " +
                   "[sep] This is a white pillow. It is on the right side of the bed."
        img4.style.width = "100%";
        img4.onclick = function() {populateDemo(img4)};

        img5.src = "assets/scene_view/captioning5.jpg"
        img5.alt = "Relay a brief summary of this scene's elements. " +
                   "[sep] In this scene, there is a tall wardrobe standing on the wooden floor. " +
                   "The wardrobe is to the right of a bed and in front of a nightstand. " +
                   "It is also behind a chair and to the left of another chair. " +
                   "There are pillows lying on the bed, with different sizes and colors. " +
                   "Some pillows are close to each other, while others are far away from each other. " +
                   "A blanket is lying on the bed, close to one of the pillows. " +
                   "The room has white walls attached to the floor, giving it an architectural feel. " +
                   "The ceiling is overhead and attached to the walls. " +
                   "There is a curtain hanging on one of the walls, adding a touch of elegance to the room. " +
                   "Overall, this room provides a cozy and comfortable space for relaxation and sleep."
        img5.style.width = "100%";
        img5.onclick = function() {populateDemo(img5)};

        img6.src = "assets/scene_view/captioning6.jpg"
        img6.alt = "Can you walk me through the details of this scene? " +
                   "[sep] In this scene, there is a white rectangular metal heater connected to the wall. " +
                   "It is in front of a curtain and to the right of another curtain. " +
                   "There is also a closed glass window attached to the wall. " +
                   "The floor is made of wooden material and has a striped texture. " +
                   "There are several chairs in the room, with different sizes and colors. " +
                   "Some chairs are close to tables, while others are far away from them. " +
                   "The walls are flat and white, giving the room an architectural feel. " +
                   "The room appears to be a living room or dining area, with comfortable seating options and a cozy atmosphere."
        img6.style.width = "100%";
        img6.onclick = function() {populateDemo(img6)};
      }

      else if (capability == "reasoning") {
        img1.src = "assets/scene_view/reasoning1.jpg"
        img1.alt = "In what part of the shower is the seat located? " +
                   "[sep] Right side of shower."

        img2.src = "assets/scene_view/reasoning2.jpg"
        img2.alt = "How many monitors sit on top of the desk? " +
                   "[sep] 2."

        img3.src = "assets/scene_view/reasoning3.jpg"
        img3.alt = "You are standing in between the toilet on your right and the sink on your left. " +
                   "Is the door closed or open to your left side? " +
                   "[sep] Closed."

        img4.src = "assets/scene_view/reasoning4.jpg"
        img4.alt = "You are sitting on a chair drinking from your bottle. " +
                   "What are you sitting at? " +
                   "[sep] Desk."
        img4.style.width = "100%";
        img4.onclick = function() {populateDemo(img4)};

        img5.src = "assets/scene_view/reasoning5.jpg"
        img5.alt = "What is the type of the room? " +
                   "[sep] Laundry room."
        img5.style.width = "100%";
        img5.onclick = function() {populateDemo(img5)};

        img6.src = "assets/scene_view/reasoning6.jpg"
        img6.alt = "Where is the player? " +
                   "[sep] Standing on the commode."
        img6.style.width = "100%";
        img6.onclick = function() {populateDemo(img6)};
      }

      else if (capability == "dialogue") {
        img1.src = "assets/scene_view/dialogue1.jpg"
        img1.alt = "I'm redecorating my bedroom and I need some advice. Can you help me? " +
                   "[sep] Of course! I'd be happy to help. What do you need advice on? " +
                   "[SEP] I want to add some color to the room. Are there any colorful decorations or objects in the room? " +
                   "[sep] Yes, there is a colorful picture hanging on the wall. It is in front of a shelf and behind an armchair. It adds a nice pop of color to the room. " +
                   "[SEP] That sounds great! What other decorations or furniture are in the room? " +
                   "[sep] There is a wardrobe to the right of a stuffed animal. It is also close to a light and in front of a doorframe. Additionally, there are shelve attached to the wall, with various item displayed on them. " +
                   "[SEP] Are there any curtains in the room? " +
                   "[sep] Yes, there are curtain hanging on the wall. They are to the left of some shelve and have a patterned texture. " +
                   "[SEP] Thank you for the information! It's really helpful for my redecorating plans. " +
                   "[sep] You're welcome! I'm glad I could help. If you have any more questions or need further assistance, feel free to ask."

        img2.src = "assets/scene_view/dialogue2.jpg"
        img2.alt = "Can you help me find the blackboard in the room? " +
                   "[sep] Yes, there is a blackboard in the room. It is located on one of the wall. " +
                   "[SEP] Thank you. I also need a chair to sit on. Where can I find a chair? " +
                   "[sep] There are several chair in the room. One chair is close to the desk, another chair is next to the radiator, and there are more chair near the table. " +
                   "[SEP] Great! I need a wide chair. " +
                   "[sep] The chair next to the desk is wide in size. You can sit on that chair. " +
                   "[SEP] Thank you for your help. " +
                   "[sep] You're welcome! If you have any other questions, feel free to ask."

        img3.src = "assets/scene_view/dialogue3.jpg"
        img3.alt = "Can you tell me about the cleanliness of the bathroom? " +
                   "[sep] Sure! The floor of the bathroom is clean and it has a tiled texture. There is a towel hanging on the wall, and it is tidy. " +
                   "[SEP] Is the toilet seat down or up? " +
                   "[sep] The toilet seat is down. " +
                   "[SEP] Is there a mirror in the bathroom? " +
                   "[sep] Yes, there is a mirror in the bathroom. " +
                   "[SEP] Is there any shampoo in the bathroom? " +
                   "[sep] Yes, there is a shampoo in the room. " +
                   "[SEP] Thank you for the information. " +
                   "[sep] You're welcome! If you have any more questions, feel free to ask."

        img4.style.width = 0
        img4.onclick = null

        img5.style.width = 0
        img5.onclick = null

        img6.style.width = 0
        img6.onclick = null
      }

      else if (capability == "planning") {
        img1.src = "assets/scene_view/planning1.jpg"
        img1.alt = "Help in setting up the task's plan: Tidy up the bedroom and neaten the clutter. " +
                   "[sep] 1. Make the bed by straightening the sheets, fluffing the pillows, and arranging the blankets.\n" +
                   "2. Vacuum or sweep the floor to remove any dirt or debris.\n" +
                   "3. Dust and clean the surfaces of the furniture, such as the desk, shelves, and wardrobe.\n" +
                   "4. Organize the items on the shelves, ensuring that they are neatly arranged.\n" +
                   "5. Remove any clutter or unnecessary items from the room.\n" +
                   "6. Check and adjust the temperature or settings of the heater if necessary."

        img2.src = "assets/scene_view/planning2.jpg"
        img2.alt = "State a plan for the task: Arrange the study room. " +
                   "[sep] 1. Dust and clean the surfaces of the furniture, such as the desk, shelves, and wardrobe.\n" +
                   "2. Organize the items on the desk, ensuring that they are neatly arranged and easily accessible.\n" +
                   "3. Adjust the curtains to the desired position, allowing natural light to enter the room.\n" +
                   "4. Arrange any personal belongings or decor items on the shelves, creating a visually pleasing display.\n" +
                   "5. Check and adjust the temperature or settings of the heater if necessary."

        img3.src = "assets/scene_view/planning3.jpg"
        img3.alt = "Can you depict a plan for the task: Arrange the furniture in the living room. " +
                   "[sep] 1. Clean the floor by sweeping or vacuuming to remove any dirt or debris.\n" +
                   "2. Arrange the chairs around the table, ensuring they are evenly spaced and facing the table.\n" +
                   "3. Adjust the position of the window blinds or curtains to control the amount of light entering the room.\n" +
                   "4. Organize the items on the shelves, ensuring they are neatly arranged and visually appealing.\n" +
                   "5. Turn on the lights in the living room to create a bright and inviting atmosphere."

        img4.style.width = 0
        img4.onclick = null

        img5.style.width = 0
        img5.onclick = null

        img6.style.width = 0
        img6.onclick = null
      }

      for (const rb of radioButtons) {rb.disabled = false}
    })
  }
  radioButtons[0].click()

  // resize renderers
  function resizeRenderers() {
    let content_width = document.querySelector('#demo').offsetWidth
    renderer1.setSize(content_width * 6.7 / 12, content_width / 1.618 * 6.7 / 12)
  }
  window.addEventListener('resize', () => {
    resizeRenderers()
  })
  resizeRenderers()

  window.model1 = model1;
  window.scene1 = scene1;
  window.assetLoader1 = assetLoader1;

</script>


</html>
